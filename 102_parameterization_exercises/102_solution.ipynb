{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install libigl matplotlib numpy polyscope gpytoolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Mesh Parameterization: Exercises\n",
    "In this notebook you will perform the same analysis you did in 101 on more complex meshes, and try your hand at more complicated parameterization techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Fixed Boundary Parameterization and Distortion Analysis ###\n",
    "In this folder you are given 2 meshes -- halfbunny.obj and ogre.obj. Load each of these meshes using gpytoolbox and use the code from notebook 101 to perform the analyses in the next few code blocks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading required packages\n",
    "import numpy as np\n",
    "import polyscope as ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 halfbunny.obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use gpytoolbox to load in halfbunny.obj\n",
    "from meshing.io import PolygonSoup\n",
    "from meshing.mesh import Mesh\n",
    "\n",
    "soup = PolygonSoup.from_obj(\"ogre.obj\")\n",
    "mesh = Mesh(soup.vertices, soup.indices)\n",
    "\n",
    "# TODO: Use the below code copied from notebook 101 to get the boundary and non-boundary edges of the imported mesh\n",
    "from igl import boundary_loop\n",
    "\n",
    "bnd = boundary_loop(mesh.faces)\n",
    "boundary_idxs = list(sorted(bnd))\n",
    "\n",
    "from igl import map_vertices_to_circle\n",
    "\n",
    "boundary_positions = map_vertices_to_circle(mesh.vertices, bnd).astype(mesh.vertices.dtype)\n",
    "\n",
    "# Resort the positions to match the order of boundary_idxs\n",
    "boundary_positions = boundary_positions[np.argsort(bnd)]\n",
    "\n",
    "pred_idxs = np.array([i for i in range(mesh.vertices.shape[0]) if i not in boundary_idxs])\n",
    "\n",
    "# Get edge array\n",
    "from collections import defaultdict\n",
    "edges = defaultdict(int)\n",
    "for f in mesh.faces:\n",
    "    for i in range(3):\n",
    "        if f[i] > f[(i+1)%3]:\n",
    "            edges[(f[(i+1)%3], f[i])] += 1\n",
    "        else:\n",
    "            edges[(f[i], f[(i+1)%3])] += 1\n",
    "\n",
    "# Valid edges are the ones that are shared by two faces\n",
    "tot_edges = np.array(list(edges.keys()))\n",
    "valid_edges = np.array([k for k, v in edges.items() if v == 2])\n",
    "boundary_edges = np.array([k for k, v in edges.items() if v == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copy over the setup_parameterization_matrices() function from notebook 101 and use it to compute\n",
    "# 1) The Tutte parameterization (all weights of 1)\n",
    "# 2) The Mean Value weights parameterization (see formula and code for computing the mean value weights from notebook 101)\n",
    "def setup_parameterization_matrices(vertices, boundary_idxs, edges, weights=1):\n",
    "    \"\"\" Set up the Tutte linear system (laplacian weights of 1)\n",
    "\n",
    "    vertices (np.ndarray): V x 3 array of vertex positions\n",
    "    boundary_idxs (np.ndarray): B array of boundary vertex indices\n",
    "    edges (np.ndarray): E x 2 array of edge indices for weight assignment\n",
    "    weights (float or np.ndarray): E array of edge weights or scalar value (default 1)\n",
    "\n",
    "    Returns:\n",
    "        L (np.ndarray): V x V Laplacian matrix with boundary values set to 0\n",
    "        Lb (np.ndarray): V x B boundary Laplacian\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the laplacian matrix\n",
    "    L = np.zeros((vertices.shape[0], vertices.shape[0]))\n",
    "\n",
    "    L[edges[:, 0], edges[:, 1]] = weights\n",
    "    L[edges[:, 1], edges[:, 0]] = weights\n",
    "\n",
    "    # Off-diagonal elements are negative and diagonal is the negative sum of the row\n",
    "    L = np.diag(np.sum(L, axis=1)) - L\n",
    "\n",
    "    # Boundary weights are positive\n",
    "    Lb = -L[:, boundary_idxs]\n",
    "\n",
    "    # Boundary diagonal should be set to 0\n",
    "    Lb[boundary_idxs, range(len(boundary_idxs))] = 0\n",
    "\n",
    "    # Set the off-diagonal boundary columns to 0\n",
    "    Ldiag = np.diag(L).copy()\n",
    "\n",
    "    L[:, boundary_idxs] = 0\n",
    "    np.fill_diagonal(L, Ldiag)\n",
    "\n",
    "    return L, Lb\n",
    "\n",
    "L, Lb = setup_parameterization_matrices(mesh.vertices, boundary_idxs, valid_edges)\n",
    "\n",
    "### Solve the Tutte linear system\n",
    "tutte_solution = np.linalg.solve(L, Lb @ boundary_positions)\n",
    "tutte_uv = np.zeros((mesh.vertices.shape[0], 2))\n",
    "tutte_uv[pred_idxs] = tutte_solution[pred_idxs]\n",
    "tutte_uv[boundary_idxs] = boundary_positions\n",
    "\n",
    "# ps.init()\n",
    "# ps.remove_all_structures()\n",
    "# ps_uv = ps.register_surface_mesh(\"tutte solution\", tutte_solution, mesh.faces, edge_width=1)\n",
    "# ps_uv = ps.register_surface_mesh(\"tutte uv\", tutte_uv, mesh.faces, edge_width=1)\n",
    "# ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copy over the setup_parameterization_matrices() function from notebook 101 and use it to compute\n",
    "# 1) The Tutte parameterization (all weights of 1)\n",
    "# 2) The Mean Value weights parameterization (see formula and code for computing the mean value weights from notebook 101)\n",
    "meanvalues = {}\n",
    "for fi in range(len(mesh.faces)):\n",
    "    f = mesh.faces[fi]\n",
    "    for i in range(3):\n",
    "        v1 = f[i]\n",
    "        v2 = f[(i+1)%3]\n",
    "        v3 = f[(i+2)%3]\n",
    "        e1 = mesh.vertices[v2] - mesh.vertices[v1]\n",
    "        e2 = mesh.vertices[v3] - mesh.vertices[v1]\n",
    "\n",
    "        b1 = mesh.vertices[v1] - mesh.vertices[v2]\n",
    "        b2 = mesh.vertices[v3] - mesh.vertices[v2]\n",
    "\n",
    "        assert (v1, v2) not in meanvalues\n",
    "\n",
    "        alpha = np.arccos(np.dot(e1, e2) / (np.linalg.norm(e1) * np.linalg.norm(e2)))\n",
    "        beta = np.arccos(np.dot(b1, b2) / (np.linalg.norm(b1) * np.linalg.norm(b2)))\n",
    "\n",
    "        meanvalues[(v1, v2)] = (np.tan(alpha/2),\n",
    "                            np.tan(beta/2),\n",
    "                            np.linalg.norm(mesh.vertices[v2] - mesh.vertices[v1]))\n",
    "\n",
    "# For each edge pair, compute the mean value weights\n",
    "mean_value_weights = np.zeros((len(valid_edges),))\n",
    "for i, edge in enumerate(valid_edges):\n",
    "    v1, v2 = edge\n",
    "\n",
    "    assert (v1, v2) in meanvalues and (v2, v1) in meanvalues\n",
    "\n",
    "    a1, b2, r1 = meanvalues[(v1, v2)]\n",
    "    a2, b1, r2 = meanvalues[(v2, v1)]\n",
    "\n",
    "    assert r1 == r2\n",
    "\n",
    "    mean_value_weights[i] = (a1 + b1)/r1\n",
    "\n",
    "L, Lb = setup_parameterization_matrices(mesh.vertices, boundary_idxs, valid_edges, weights=mean_value_weights)\n",
    "\n",
    "### Solve the Tutte linear system\n",
    "mean_value_solution = np.linalg.solve(L, Lb @ boundary_positions)\n",
    "\n",
    "# Bring solution back to final UVs\n",
    "mean_value_uv = np.zeros_like(mesh.vertices[:, :2])\n",
    "mean_value_uv[boundary_idxs] = boundary_positions\n",
    "mean_value_uv[pred_idxs] = mean_value_solution[pred_idxs]\n",
    "\n",
    "# ps.init()\n",
    "# ps.remove_all_structures()\n",
    "# ps_uv = ps.register_surface_mesh(\"meanvalue\", mean_value_uv, mesh.faces, edge_width=1)\n",
    "# ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"ogre_tutte.npy\", tutte_uv)\n",
    "np.save(\"ogre_meanvalue.npy\", mean_value_uv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean conformal energy:  4.729862835966947\n",
      "Mean isometric energy:  42862123.760993205\n",
      "Mean conformal energy:  0.016295271\n",
      "Mean isometric energy:  335560500.0\n"
     ]
    }
   ],
   "source": [
    "J = get_jacobian(mesh.vertices, mesh.faces, tutte_uv)\n",
    "\n",
    "_, S, _ = np.linalg.svd(J)\n",
    "\n",
    "E_conformal = (S[:, 0] - S[:, 1])**2\n",
    "E_isometric = S[:, 0]**2 + S[:, 1]**2 + 1/(S[:, 0]**2) + 1/(S[:, 1]**2) - 4\n",
    "print(\"Mean conformal energy: \", np.mean(E_conformal))\n",
    "print(\"Mean isometric energy: \", np.mean(E_isometric))\n",
    "\n",
    "J = get_jacobian(mesh.vertices, mesh.faces, mean_value_uv)\n",
    "\n",
    "_, S, _ = np.linalg.svd(J)\n",
    "\n",
    "E_conformal = (S[:, 0] - S[:, 1])**2\n",
    "E_isometric = S[:, 0]**2 + S[:, 1]**2 + 1/(S[:, 0]**2) + 1/(S[:, 1]**2) - 4\n",
    "print(\"Mean conformal energy: \", np.mean(E_conformal))\n",
    "print(\"Mean isometric energy: \", np.mean(E_isometric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: LSCM and ARAP ###\n",
    "In this part you will use two more advanced parameterization techniques to flatten the same meshes. \n",
    "\n",
    "These two methods are Least Squares Conformal Maps [(LSCM)](https://www.cs.jhu.edu/~misha/Fall09/Levy02.pdf) and As-Rigid-As-Possible Mesh Parameterization [(ARAP)](https://cs.harvard.edu/~sjg/papers/arap.pdf). \n",
    "\n",
    "As you will see, these are two examples of **free boundary** methods (though LSCM technically requires two vertices to be pinned), which allows the boundary to move independently to perform the desired distortion minimization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Least Squares Conformal Maps [(LSCM)](https://www.cs.jhu.edu/~misha/Fall09/Levy02.pdf)\n",
    "As the name implies, LSCM is a **conformal** method, meaning it aims to minimize the conformal (angular) distortion of the parameterization, using a least squares solve. Deriving and computing this method by hand is beyond the scope of this exercise, so we will be using libigl's `lscm()` function to do the computation for us. \n",
    "\n",
    "One important note is that LSCM requires two vertices to be pinned in the plane to make the least-squared system well-determined (so there is a unique solution). Technically any two vertices can be chosen, but in practice vertices at the opposite end of a boundary loop are usually the best choice for method performance. The code commented below gives an example of computing the LSCM parameterization using libigl. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use gpytoolbox to load in halfbunny.obj\n",
    "from meshing.io import PolygonSoup\n",
    "from meshing.mesh import Mesh\n",
    "\n",
    "soup = PolygonSoup.from_obj(\"ogre.obj\")\n",
    "mesh = Mesh(soup.vertices, soup.indices)\n",
    "\n",
    "# TODO: Use the below code copied from notebook 101 to get the boundary and non-boundary edges of the imported mesh\n",
    "from igl import boundary_loop\n",
    "\n",
    "bnd = boundary_loop(mesh.faces)\n",
    "boundary_idxs = list(sorted(bnd))\n",
    "\n",
    "from igl import map_vertices_to_circle\n",
    "\n",
    "boundary_positions = map_vertices_to_circle(mesh.vertices, bnd).astype(mesh.vertices.dtype)\n",
    "\n",
    "# Resort the positions to match the order of boundary_idxs\n",
    "boundary_positions = boundary_positions[np.argsort(bnd)]\n",
    "\n",
    "pred_idxs = np.array([i for i in range(mesh.vertices.shape[0]) if i not in boundary_idxs])\n",
    "\n",
    "# Get edge array\n",
    "from collections import defaultdict\n",
    "edges = defaultdict(int)\n",
    "for f in mesh.faces:\n",
    "    for i in range(3):\n",
    "        if f[i] > f[(i+1)%3]:\n",
    "            edges[(f[(i+1)%3], f[i])] += 1\n",
    "        else:\n",
    "            edges[(f[i], f[(i+1)%3])] += 1\n",
    "\n",
    "# Valid edges are the ones that are shared by two faces\n",
    "tot_edges = np.array(list(edges.keys()))\n",
    "valid_edges = np.array([k for k, v in edges.items() if v == 2])\n",
    "boundary_edges = np.array([k for k, v in edges.items() if v == 1])\n",
    "\n",
    "from igl import boundary_loop, lscm\n",
    "\n",
    "bdry = boundary_loop(mesh.faces)\n",
    "\n",
    "b = np.array([bdry[0], bdry[int(len(bdry)/2)]], dtype=\"int\")\n",
    "bc = np.array([[0, 0], [1, 1]], dtype=np.float32)\n",
    "succ, lscm_uv = lscm(mesh.vertices, mesh.faces, b, bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.init()\n",
    "ps.remove_all_structures()\n",
    "ps_uv = ps.register_surface_mesh(\"lscm\", lscm_uv, mesh.faces, edge_width=1)\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean conformal energy:  0.0008202818835717025\n",
      "Mean isometric energy:  1155.7294863619238\n"
     ]
    }
   ],
   "source": [
    "def get_jacobian(vs, fs, uvmap):\n",
    "    \"\"\" Get jacobian of mesh given an input UV map\n",
    "\n",
    "    Args:\n",
    "        vs (np.ndarray): V x 3 array of vertex positions\n",
    "        fs (np.ndarray): F x 3 integer array of face indices\n",
    "        uvmap (np.ndarray): V x 2 array of UV coordinates\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # Visualize distortion\n",
    "    from igl import grad\n",
    "    G = np.array(grad(vs, fs).todense())\n",
    "\n",
    "    # NOTE: currently gradient is organized as X1, X2, X3, ... Y1, Y2, Y3, ... Z1, Z2, Z3 ... reshape to X1, Y1, Z1, ...\n",
    "    splitind = G.shape[0]//3\n",
    "    newG = np.zeros_like(G) # F*3 x V\n",
    "    newG[::3] = G[:splitind]\n",
    "    newG[1::3] = G[splitind:2*splitind]\n",
    "    newG[2::3] = G[2*splitind:]\n",
    "\n",
    "    J = (newG @ uvmap).reshape(-1, 3, 2) # F x 3 x 2\n",
    "    return J\n",
    "\n",
    "J = get_jacobian(mesh.vertices, mesh.faces, lscm_uv)\n",
    "\n",
    "_, S, _ = np.linalg.svd(J)\n",
    "\n",
    "E_conformal = (S[:, 0] - S[:, 1])**2\n",
    "E_isometric = S[:, 0]**2 + S[:, 1]**2 + 1/(S[:, 0]**2) + 1/(S[:, 1]**2) - 4\n",
    "print(\"Mean conformal energy: \", np.mean(E_conformal))\n",
    "print(\"Mean isometric energy: \", np.mean(E_isometric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 As-Rigid-As-Possible Mesh Parameterization [(ARAP)](https://cs.harvard.edu/~sjg/papers/arap.pdf)\n",
    "The ARAP method aims to minimize isometric distortion (both area and angles), using a non-linear algorithm which alternates between local and global optimization steps. The method requires an initial UV map as input, so we use a harmonic parameterization as an initial guess. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use the below example code to compute the ARAP parameterization of halfbunny.obj and ogre.obj\n",
    "from igl import ARAP, boundary_loop, harmonic, map_vertices_to_circle\n",
    "bnd = boundary_loop(mesh.faces)\n",
    "bnd_uv = map_vertices_to_circle(mesh.vertices, bnd).astype(mesh.vertices.dtype)\n",
    "initial_uv = harmonic(mesh.vertices, mesh.faces, bnd, bnd_uv, 1)\n",
    "arap = ARAP(mesh.vertices, mesh.faces, 2, np.zeros(0), with_dynamics=True)\n",
    "arap_uv = arap.solve(np.zeros((0,0)), initial_uv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.init()\n",
    "ps.remove_all_structures()\n",
    "ps_uv = ps.register_surface_mesh(\"arap\", arap_uv, mesh.faces, edge_width=1)\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean conformal energy:  0.24614305519835683\n",
      "Mean isometric energy:  4296.2617408718015\n"
     ]
    }
   ],
   "source": [
    "J = get_jacobian(mesh.vertices, mesh.faces, arap_uv)\n",
    "\n",
    "_, S, _ = np.linalg.svd(J)\n",
    "\n",
    "E_conformal = (S[:, 0] - S[:, 1])**2\n",
    "E_isometric = S[:, 0]**2 + S[:, 1]**2 + 1/(S[:, 0]**2) + 1/(S[:, 1]**2) - 4\n",
    "print(\"Mean conformal energy: \", np.mean(E_conformal))\n",
    "print(\"Mean isometric energy: \", np.mean(E_isometric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"halfbunny_lscm.npy\", lscm_uv)\n",
    "np.save(\"halfbunny_arap.npy\", arap_uv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
